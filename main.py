import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPRegressor # ุงู ูููู ูุบุฒ ูุตููุน ุงุณุช
from sklearn.preprocessing import StandardScaler # ุงูู ุงุจุฒุงุฑ ฺฉูฺฺฉโุณุงุฒ ุงุนุฏุงุฏ
from sklearn.metrics import r2_score, mean_absolute_error

# 1. ููุฏ ู ุชุฑฺฉุจ ุฏุชุง
print("โณ ุงุณุชุงุฑุช ููุชูุฑ ุฏูพ ูุฑููฺฏ...")
try:
    df2023 = pd.read_csv('2023_Tehran_House_Price.csv')
    df2024 = pd.read_csv('2024_Tehran_House_Price.csv')
    df = pd.concat([df2023, df2024], ignore_index=True)
except:
    print("โ ูุงูโูุง ูุณุชู!")
    exit()

# 2. ุชูุฒฺฉุงุฑ (ูุซู ูุจู)
df = df[~df['Address'].str.contains('ุชุณุช', na=False)]
df = df[(df['Meter'] >= 30) & (df['Meter'] <= 500)]
df['Price_Billion'] = df['Price'] / 10_000_000_000
df = df[(df['Price_Billion'] > 0.2) & (df['Price_Billion'] < 200)]

# 3. ุขูุงุฏูโุณุงุฒ ูพุดุฑูุชู (Encoding)
top_regions = df['Region'].value_counts().head(50).index
df_filtered = df[df['Region'].isin(top_regions)].copy()
df_encoded = pd.get_dummies(df_filtered, columns=['Region'], drop_first=True)

features = ['Meter', 'Age', 'Rooms', 'Parking', 'Elevator'] + [col for col in df_encoded.columns if 'Region_' in col]
X = df_encoded[features]
y = df_encoded['Price_Billion']

# 4. ุชูุณู ุฏุงุฏูโูุง
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# --- ุจุฎุด ุฌุฏุฏ ู ุญุงุช: ุงุณุชุงูุฏุงุฑุฏุณุงุฒ (Scaling) ---
# ุงุนุฏุงุฏ ุฑู ุจุฑุง ุดุจฺฉู ุนุตุจ ูุงุจู ููู ูโฺฉูู
print("โ๏ธ ุฏุฑ ุญุงู ุงุณุชุงูุฏุงุฑุฏ ฺฉุฑุฏู ุงุนุฏุงุฏ (Scaling)...")
scaler_X = StandardScaler()
scaler_y = StandardScaler()

# ูุช ฺฉุฑุฏู ุฑู ุฏุงุฏูโูุง ุขููุฒุด (ุงุฏฺฏุฑ ูุงูฺฏู ู ุงูุญุฑุงู ูุนุงุฑ)
X_train_scaled = scaler_X.fit_transform(X_train)
y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()

# ุฏุงุฏูโูุง ุชุณุช ุฑู ูู ุจุง ูููู ููุงุณ ฺฉูฺฺฉ ูโฺฉูู
X_test_scaled = scaler_X.transform(X_test)

# 5. ุณุงุฎุช ูุบุฒ ูุตููุน (Neural Network)
print("๐ง ุฏุฑ ุญุงู ุณุงุฎุช ู ุขููุฒุด ุดุจฺฉู ุนุตุจ (ุงู ููฺฉูู ฺฉู ุทูู ุจฺฉุดู)...")
# hidden_layer_sizes=(100, 50) ุนู:
# ูุงู ุงูู: ฑฐฐ ุชุง ููุฑูู (ุณููู ูุบุฒ)
# ูุงู ุฏูู: ตฐ ุชุง ููุฑูู
# max_iter=500: ุนู ตฐฐ ุจุงุฑ ฺฉู ุฏุฑุณโูุง ุฑู ูุฑูุฑ ฺฉู
model = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', max_iter=500, random_state=42)
model.fit(X_train_scaled, y_train_scaled)

# 6. ุงูุชุญุงู ููุง
print("๐ ุฏุฑ ุญุงู ุชุตุญุญ ุจุฑฺฏู ุงูุชุญุงู...")
y_pred_scaled = model.predict(X_test_scaled)
# ุจุงุฏ ุงุนุฏุงุฏ ุฑู ุงุฒ ุญุงูุช ุงุณุชุงูุฏุงุฑุฏ ุจุฑฺฏุฑุฏููู ุจู ุญุงูุช ููุงุฑุฏ (Inverse Transform)
y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()

r2 = r2_score(y_test, y_pred) * 100
mae = mean_absolute_error(y_test, y_pred)

print("\n" + "*"*40)
print(f"๐ฅ ููุฑู ููุด ุดุจฺฉู ุนุตุจ (R2): {r2:.2f} ุงุฒ ฑฐฐ")
print(f"๐ ุฎุทุง ูุฏู: {mae:.2f} ููุงุฑุฏ ุชููุงู")
print("*"*40)

# ููุงุณู ุจุง ูุฏู ูุจู
if r2 > 79.0:
    print("โ ุงูู! ุดุจฺฉู ุนุตุจ ุงุฒ ูุฏู ุฎุท ูุจู ุจุงููุดโุชุฑ ุนูู ฺฉุฑุฏ.")
else:
    print("โ๏ธ ูฺฉุชู: ฺฏุงู ุฑู ุฏุงุฏูโูุง ุณุงุฏูุ ูุฏู ุฎุท ุจูุชุฑ ุฌูุงุจ ูุฏู (ุง ุจุงุฏ ูุงูโูุง ุฑู ุชุบุฑ ุจุฏู).")

import joblib

# ุฐุฎุฑู ฺฉุฑุฏู ูุบุฒ ูุฏู (model) ู ูุชุฑุฌูโูุง (scaler)
print("๐พ ุฏุฑ ุญุงู ุฐุฎุฑู ุณุงุฒ ูุฏู...")
joblib.dump(model, 'tehran_house_model.pkl')
joblib.dump(scaler_X, 'scaler_X.pkl')
joblib.dump(scaler_y, 'scaler_y.pkl')
print("โ ูุฏู ุดูุง ุฏุฑ ูุงู 'tehran_house_model.pkl' ุฐุฎุฑู ุดุฏ. ุงู ูุงู ุนู ุชูุงู ููุด ูุตููุน ุดูุง!")